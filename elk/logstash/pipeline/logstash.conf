# elk/logstash/pipeline/logstash.conf
input {
  # 监听 50000 端口，接收 TCP 数据流
  # codec => "json_lines" 告诉它每行都是一个独立的 JSON 对象
  tcp {
    port => 50000
    codec => "json_lines"
  }
}

# filter 部分可以保持不变，或者暂时移除以简化
# 因为 python-logstash-async 已经发送了很好的 JSON 格式
filter {
  # 无需额外 filter，日志已经是结构化的
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "fastapi-direct-%{+YYYY.MM.dd}"
  }
}